#!/usr/bin/env python3
"""
S3ãƒã‚±ãƒƒãƒˆã®å†…å®¹ã‚’è©³ã—ãç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import boto3
from botocore.exceptions import NoCredentialsError, ClientError
import sys
from datetime import datetime


def load_env_file(env_path='.env'):
    """
    .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã™ã‚‹
    """
    if not os.path.exists(env_path):
        print(f"âš ï¸  {env_path} ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    try:
        with open(env_path, 'r', encoding='utf-8') as file:
            for line in file:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                if '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()
                    
                    if (value.startswith('"') and value.endswith('"')) or \
                       (value.startswith("'") and value.endswith("'")):
                        value = value[1:-1]
                    
                    if key not in os.environ:
                        os.environ[key] = value
        
        return True
        
    except Exception as e:
        print(f"âŒ {env_path} ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return False


def get_s3_client():
    """
    S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    """
    aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')
    aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
    region_name = os.environ.get('AWS_S3_REGION_NAME', 'ap-northeast-1')
    
    if not aws_access_key_id or not aws_secret_access_key:
        print("âŒ AWSèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None
    
    try:
        return boto3.client(
            's3',
            aws_access_key_id=aws_access_key_id,
            aws_secret_access_key=aws_secret_access_key,
            region_name=region_name
        )
    except Exception as e:
        print(f"âŒ S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆã«å¤±æ•—: {e}")
        return None


def list_all_objects(s3_client, bucket_name):
    """
    ãƒã‚±ãƒƒãƒˆå†…ã®ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¸€è¦§è¡¨ç¤º
    """
    print(f"ğŸ“‚ ãƒã‚±ãƒƒãƒˆ '{bucket_name}' ã®å…¨å†…å®¹:")
    
    try:
        paginator = s3_client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=bucket_name)
        
        total_objects = 0
        total_size = 0
        folders = {}
        
        for page in pages:
            if 'Contents' in page:
                for obj in page['Contents']:
                    total_objects += 1
                    total_size += obj['Size']
                    
                    # ãƒ•ã‚©ãƒ«ãƒ€åˆ¥ã«åˆ†é¡
                    key = obj['Key']
                    if '/' in key:
                        folder = key.split('/')[0]
                        if folder not in folders:
                            folders[folder] = {'count': 0, 'size': 0, 'files': []}
                        folders[folder]['count'] += 1
                        folders[folder]['size'] += obj['Size']
                        folders[folder]['files'].append({
                            'key': key,
                            'size': obj['Size'],
                            'modified': obj['LastModified']
                        })
                    else:
                        # ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«
                        if 'root' not in folders:
                            folders['root'] = {'count': 0, 'size': 0, 'files': []}
                        folders['root']['count'] += 1
                        folders['root']['size'] += obj['Size']
                        folders['root']['files'].append({
                            'key': key,
                            'size': obj['Size'],
                            'modified': obj['LastModified']
                        })
        
        if total_objects == 0:
            print("   ãƒã‚±ãƒƒãƒˆã¯ç©ºã§ã™")
            return
        
        print(f"   ç·ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {total_objects:,}")
        print(f"   ç·ã‚µã‚¤ã‚º: {total_size / 1024 / 1024:.2f} MB")
        print()
        
        # ãƒ•ã‚©ãƒ«ãƒ€åˆ¥ã®è©³ç´°ã‚’è¡¨ç¤º
        for folder_name, folder_info in folders.items():
            if folder_name == 'root':
                print("ğŸ“ ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«:")
            else:
                print(f"ğŸ“ {folder_name}/:")
            
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {folder_info['count']}")
            print(f"   åˆè¨ˆã‚µã‚¤ã‚º: {folder_info['size'] / 1024:.1f} KB")
            
            # æœ€æ–°ã®5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
            recent_files = sorted(folder_info['files'], 
                                key=lambda x: x['modified'], reverse=True)[:5]
            
            for file_info in recent_files:
                size_kb = file_info['size'] / 1024
                modified_str = file_info['modified'].strftime("%Y-%m-%d %H:%M:%S")
                print(f"   - {file_info['key']} ({size_kb:.1f} KB, {modified_str})")
            
            if len(folder_info['files']) > 5:
                print(f"   ... ä»– {len(folder_info['files']) - 5} ãƒ•ã‚¡ã‚¤ãƒ«")
            print()
            
    except ClientError as e:
        error_code = e.response['Error']['Code']
        if error_code == '404':
            print(f"âŒ ãƒã‚±ãƒƒãƒˆ '{bucket_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        elif error_code == '403':
            print(f"âŒ ãƒã‚±ãƒƒãƒˆ '{bucket_name}' ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            print(f"âŒ ãƒã‚±ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        print(f"âŒ ãƒã‚±ãƒƒãƒˆå†…å®¹ã®å–å¾—ã«å¤±æ•—: {e}")


def check_push_notification_icons(s3_client, bucket_name):
    """
    ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã‚¢ã‚¤ã‚³ãƒ³ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª
    """
    print("ğŸ”” ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã‚¢ã‚¤ã‚³ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª:")
    
    prefixes = [
        'media/push_notification_icons/',
        'push_notification_icons/',
        'media/'
    ]
    
    for prefix in prefixes:
        try:
            response = s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix=prefix,
                MaxKeys=10
            )
            
            if 'Contents' in response:
                print(f"   âœ… {prefix} ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã™")
                print(f"      ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(response['Contents'])}")
                for obj in response['Contents']:
                    size_kb = obj['Size'] / 1024
                    print(f"      - {obj['Key']} ({size_kb:.1f} KB)")
            else:
                print(f"   âšª {prefix} ãƒ•ã‚©ãƒ«ãƒ€ã¯ç©ºã§ã™")
                
        except Exception as e:
            print(f"   âŒ {prefix} ãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèªã«å¤±æ•—: {e}")


def check_recent_uploads(s3_client, bucket_name, hours=24):
    """
    æœ€è¿‘ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
    """
    print(f"â° éå»{hours}æ™‚é–“ä»¥å†…ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    
    try:
        from datetime import timedelta
        cutoff_time = datetime.now().replace(tzinfo=None) - timedelta(hours=hours)
        
        response = s3_client.list_objects_v2(Bucket=bucket_name)
        
        if 'Contents' not in response:
            print("   ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        recent_files = []
        for obj in response['Contents']:
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’å‰Šé™¤ã—ã¦æ¯”è¼ƒ
            obj_time = obj['LastModified'].replace(tzinfo=None)
            if obj_time > cutoff_time:
                recent_files.append(obj)
        
        if not recent_files:
            print(f"   éå»{hours}æ™‚é–“ä»¥å†…ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ã‚ã‚Šã¾ã›ã‚“")
            return
        
        # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
        recent_files.sort(key=lambda x: x['LastModified'], reverse=True)
        
        print(f"   {len(recent_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
        for obj in recent_files:
            size_kb = obj['Size'] / 1024
            modified_str = obj['LastModified'].strftime("%Y-%m-%d %H:%M:%S")
            print(f"   - {obj['Key']} ({size_kb:.1f} KB, {modified_str})")
            
    except Exception as e:
        print(f"âŒ æœ€è¿‘ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®ç¢ºèªã«å¤±æ•—: {e}")


def generate_presigned_urls(s3_client, bucket_name):
    """
    æœ€æ–°ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ç½²åä»˜ãURLã‚’ç”Ÿæˆ
    """
    print("ğŸ”— æœ€æ–°ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ç½²åä»˜ãURL:")
    
    try:
        response = s3_client.list_objects_v2(Bucket=bucket_name)
        
        if 'Contents' not in response:
            print("   ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.webp']
        image_files = []
        
        for obj in response['Contents']:
            key = obj['Key'].lower()
            if any(key.endswith(ext) for ext in image_extensions):
                image_files.append(obj)
        
        if not image_files:
            print("   ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # æœ€æ–°ã®3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        image_files.sort(key=lambda x: x['LastModified'], reverse=True)
        latest_images = image_files[:3]
        
        for obj in latest_images:
            try:
                # ç½²åä»˜ãURLç”Ÿæˆï¼ˆ1æ™‚é–“æœ‰åŠ¹ï¼‰
                url = s3_client.generate_presigned_url(
                    'get_object',
                    Params={'Bucket': bucket_name, 'Key': obj['Key']},
                    ExpiresIn=3600
                )
                
                size_kb = obj['Size'] / 1024
                modified_str = obj['LastModified'].strftime("%Y-%m-%d %H:%M:%S")
                print(f"   ğŸ“¸ {obj['Key']} ({size_kb:.1f} KB, {modified_str})")
                print(f"      URL: {url}")
                print()
                
            except Exception as e:
                print(f"   âŒ {obj['Key']} ã®URLç”Ÿæˆã«å¤±æ•—: {e}")
                
    except Exception as e:
        print(f"âŒ ç½²åä»˜ãURLç”Ÿæˆã«å¤±æ•—: {e}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    print("=== S3ãƒã‚±ãƒƒãƒˆå†…å®¹ç¢ºèª ===\n")
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    if not load_env_file():
        return False
    
    # S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    s3_client = get_s3_client()
    if not s3_client:
        return False
    
    bucket_name = os.environ.get('AWS_STORAGE_BUCKET_NAME')
    if not bucket_name:
        print("âŒ ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    print(f"ğŸª£ ãƒã‚±ãƒƒãƒˆå: {bucket_name}")
    print(f"ğŸŒ ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {os.environ.get('AWS_S3_REGION_NAME', 'ap-northeast-1')}")
    print()
    
    # ãƒã‚±ãƒƒãƒˆå†…å®¹ã®ä¸€è¦§è¡¨ç¤º
    list_all_objects(s3_client, bucket_name)
    
    # ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã‚¢ã‚¤ã‚³ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª
    check_push_notification_icons(s3_client, bucket_name)
    print()
    
    # æœ€è¿‘ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ç¢ºèª
    check_recent_uploads(s3_client, bucket_name)
    print()
    
    # ç½²åä»˜ãURLã‚’ç”Ÿæˆ
    generate_presigned_urls(s3_client, bucket_name)
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)